// ğŸ¤– OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸
import { Injectable, Logger } from '@nestjs/common';
import { OpenAIConfig } from '../config/openai.config';
import OpenAI from 'openai';
import { File } from '@web-std/file';
import * as zlib from 'zlib';
import { promisify } from 'util';

// gzip ì••ì¶•/í•´ì œ í•¨ìˆ˜ë¥¼ í”„ë¡œë¯¸ìŠ¤ë¡œ ë³€í™˜
const gzipAsync = promisify(zlib.gzip);
const gunzipAsync = promisify(zlib.gunzip);

// ğŸ”Œ OpenAI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ - OpenAI APIì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬
@Injectable()
export class OpenAIService {
  // OpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•˜ëŠ” private ë³€ìˆ˜
  private readonly logger = new Logger(OpenAIService.name);
  private readonly openai: OpenAI;

  // âš¡ OpenAIConfigë¥¼ ì£¼ì…ë°›ì•„ OpenAI ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
  constructor(private readonly openaiConfig: OpenAIConfig) {
    this.openai = this.openaiConfig.getOpenAI();
  }

  // ğŸ¤ï¸ ë°ì´í„° ì••ì¶• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  private async compressBuffer(buffer: Buffer): Promise<Buffer> {
    try {
      // GZIP ì••ì¶• ìˆ˜í–‰
      return await gzipAsync(buffer);
    } catch (error) {
      this.logger.error(`Error in compressBuffer: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¤ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Speech-to-Text)
  async speechToText(audioData: Buffer): Promise<string> {
    try {
      this.logger.debug('Converting speech to text');
      // ë°›ì€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([audioData], 'audio.wav', { type: 'audio/wav' });
      // Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcription = await this.openai.audio.transcriptions.create({
        file,
        model: 'whisper-1',
      });

      this.logger.debug('Speech to text result:', transcription.text + '\n\n');
      return transcription.text;
    } catch (error) {
      this.logger.error(`Error in speechToText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ’­ í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ - GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• í…ìŠ¤íŠ¸ ìƒì„±
  async generateText(prompt: string, userInput?: string): Promise<string> {
    try {
      this.logger.debug('Generating text with prompt:', prompt + '\n\n');
      // GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
      const messages: { role: 'system' | 'user' | 'assistant', content: string }[] = [
        { role: 'system', content: prompt }
      ];
      
      // ì‚¬ìš©ì ì…ë ¥ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
      if (userInput) {
        messages.push({ role: 'user', content: userInput });
      }

      const completion = await this.openai.chat.completions.create({
        messages,
        model: 'gpt-3.5-turbo',
      });

      const response = completion.choices[0].message.content;
      this.logger.debug('Generated text:', response + '\n\n');
      return response;
    } catch (error) {
      this.logger.error(`Error in generateText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Text-to-Speech)
  async textToSpeech(text: string): Promise<Buffer> { // ë°˜í™˜ íƒ€ì…ì„ Bufferë¡œ ë³€ê²½
    try {
      this.logger.debug('Converting text to speech:', text);
      // TTS-1 ëª¨ë¸ê³¼ Nova ìŒì„±ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ MP3 í˜•ì‹ ìŒì„±ìœ¼ë¡œ ë³€í™˜
      const audioResponse = await this.openai.audio.speech.create({
        model: 'tts-1',
        voice: 'nova',
        input: text,
        response_format: 'mp3', // ğŸµ MP3 í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ ë³€ê²½ (ë” ì‘ì€ íŒŒì¼ í¬ê¸°)
        speed: 1.0 // ìŒì„± ì†ë„ ì¡°ì ˆ (1.0ì´ ê¸°ë³¸)
      });

      // ğŸ”„ ì‘ë‹µì„ Bufferë¡œ ë³€í™˜í•˜ê³  ì••ì¶•
      const buffer = Buffer.from(await audioResponse.arrayBuffer());
      // const compressedBuffer = await this.compressBuffer(buffer);
      
      this.logger.debug('Text to speech conversion and compression completed');
      return buffer;
    } catch (error) {
      this.logger.error(`Error in textToSpeech: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¨ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ - DALL-E ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
  async generateImage(prompt: string): Promise<string> {
    try {
      this.logger.debug('Generating image with prompt:', prompt);
      
      const response = await this.openai.images.generate({
        model: "dall-e-3",
        prompt,
        n: 1,
        size: "1024x1024",
        quality: "standard",
        style: "natural"
      });

      const imageUrl = response.data[0].url;
      this.logger.debug('Generated image URL:', imageUrl);
      
      return imageUrl;
    } catch (error) {
      this.logger.error(`Error in generateImage: ${error.message}`, error.stack);
      throw error;
    }
  }

  /**
   * ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeImage(imageUrl: string, prompt: string): Promise<string> {
    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              { type: 'text', text: prompt },
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              }
            ]
          }
        ],
        max_tokens: 500
      });

      return response.choices[0]?.message?.content || '';
    } catch (error) {
      this.logger.error(`Error analyzing image: ${error.message}`, error.stack);
      throw new Error('ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }
}