// ğŸ¤– OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸
import { Injectable } from '@nestjs/common';
import { OpenAIConfig } from '../config/openai.config';
import OpenAI from 'openai';
import { File } from '@web-std/file';

// ğŸ”Œ OpenAI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ - OpenAI APIì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬
@Injectable()
export class OpenAIService {
  // OpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•˜ëŠ” private ë³€ìˆ˜
  private readonly openai: OpenAI;

  // âš¡ OpenAIConfigë¥¼ ì£¼ì…ë°›ì•„ OpenAI ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
  constructor(private readonly openaiConfig: OpenAIConfig) {
    this.openai = this.openaiConfig.getOpenAI();
  }

  // ğŸ¤ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Speech-to-Text)
  async speechToText(audioData: Buffer): Promise<string> {
    // ë°›ì€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
    const file = new File([audioData], 'audio.wav', { type: 'audio/wav' });
    // Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    const transcription = await this.openai.audio.transcriptions.create({
      file,
      model: 'whisper-1',
    });

    return transcription.text;
  }

  // ğŸ’­ í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ - GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• í…ìŠ¤íŠ¸ ìƒì„±
  async generateText(prompt: string): Promise<string> {
    // GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
    const completion = await this.openai.chat.completions.create({
      messages: [{ role: 'user', content: prompt }],
      model: 'gpt-3.5-turbo',
    });

    // ìƒì„±ëœ ì‘ë‹µ ì¤‘ ì²« ë²ˆì§¸ ì„ íƒì§€ì˜ ë‚´ìš©ì„ ë°˜í™˜
    return completion.choices[0].message.content;
  }

  // ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Text-to-Speech)
  async textToSpeech(text: string): Promise<Buffer> {
    // TTS-1 ëª¨ë¸ê³¼ Nova ìŒì„±ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    const mp3 = await this.openai.audio.speech.create({
      model: 'tts-1',
      voice: 'nova',
      input: text,
    });

    // ìƒì„±ëœ ìŒì„±ì„ Bufferë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    const buffer = Buffer.from(await mp3.arrayBuffer());
    return buffer;
  }
} 