// ğŸ¤– OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸
import { Injectable, Logger } from '@nestjs/common';
import { OpenAIConfig } from '../config/openai.config';
import OpenAI from 'openai';
import { File } from '@web-std/file';
import * as zlib from 'zlib';
import { promisify } from 'util';

// gzip ì••ì¶•/í•´ì œ í•¨ìˆ˜ë¥¼ í”„ë¡œë¯¸ìŠ¤ë¡œ ë³€í™˜
const gzipAsync = promisify(zlib.gzip);
const gunzipAsync = promisify(zlib.gunzip);

// ğŸ”Œ OpenAI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ - OpenAI APIì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬
@Injectable()
export class OpenAIService {
  // OpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•˜ëŠ” private ë³€ìˆ˜
  private readonly logger = new Logger(OpenAIService.name);
  private readonly openai: OpenAI;

  // âš¡ OpenAIConfigë¥¼ ì£¼ì…ë°›ì•„ OpenAI ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
  constructor(private readonly openaiConfig: OpenAIConfig) {
    this.openai = this.openaiConfig.getOpenAI();
  }

  // ğŸ¤ï¸ ë°ì´í„° ì••ì¶• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  private async compressBuffer(buffer: Buffer): Promise<Buffer> {
    try {
      // GZIP ì••ì¶• ìˆ˜í–‰
      return await gzipAsync(buffer);
    } catch (error) {
      this.logger.error(`Error in compressBuffer: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¤ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Speech-to-Text)
  async speechToText(audioData: Buffer): Promise<string> {
    try {
      this.logger.debug('Converting speech to text');
      // ë°›ì€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([audioData], 'audio.wav', { type: 'audio/wav' });
      // Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcription = await this.openai.audio.transcriptions.create({
        file,
        model: 'whisper-1',
      });

      this.logger.debug('Speech to text result:', transcription.text + '\n\n');
      return transcription.text;
    } catch (error) {
      this.logger.error(`Error in speechToText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ’­ í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ - GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• í…ìŠ¤íŠ¸ ìƒì„±
  async generateText(prompt: string, userInput?: string): Promise<string> {
    try {
      this.logger.debug('Generating text with prompt:', prompt + '\n\n');
      // GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
      const messages: { role: 'system' | 'user' | 'assistant', content: string }[] = [
        { role: 'system', content: prompt }
      ];
      
      // ì‚¬ìš©ì ì…ë ¥ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
      if (userInput) {
        messages.push({ role: 'user', content: userInput });
      }

      const completion = await this.openai.chat.completions.create({
        messages,
        model: 'gpt-4o',
      });

      const response = completion.choices[0].message.content;
      this.logger.debug('Generated text:', response + '\n\n');
      return response;
    } catch (error) {
      this.logger.error(`Error in generateText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ” ë¶„ì„ìš© í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ (GPT-4 ëª¨ë¸ ì‚¬ìš©)
  async generateAnalysis(systemPrompt: string | OpenAI.Chat.ChatCompletionMessageParam[], userPrompt?: string): Promise<string> {
    try {
      this.logger.debug('Generating analysis with system prompt:', systemPrompt);
      this.logger.debug('User prompt for analysis:', userPrompt);

      let messages: OpenAI.Chat.ChatCompletionMessageParam[];

      if (Array.isArray(systemPrompt)) {
        messages = systemPrompt;
      } else {
        messages = [
          { role: 'user' as const, content: `${systemPrompt}\n\n${userPrompt || ''}` }
        ];
      }

      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages,
        max_completion_tokens: 500,
      });

      const response = completion.choices[0]?.message?.content || '';
      this.logger.debug('Raw AI response:', response);

      // ì‘ë‹µì—ì„œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
      const cleanedResponse = response.replace(/```(?:json)?\n|\n```/g, '').trim();
      this.logger.debug('Cleaned response:', cleanedResponse);

      return cleanedResponse;
    } catch (error) {
      this.logger.error('Error generating analysis:', error);
      throw error;
    }
  }

  // ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Text-to-Speech)
  async textToSpeech(text: string): Promise<Buffer> { // ë°˜í™˜ íƒ€ì…ì„ Bufferë¡œ ë³€ê²½
    try {
      this.logger.debug('Converting text to speech:', text);
      // TTS-1 ëª¨ë¸ê³¼ Nova ìŒì„±ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ MP3 í˜•ì‹ ìŒì„±ìœ¼ë¡œ ë³€í™˜
      const audioResponse = await this.openai.audio.speech.create({
        model: 'tts-1',
        voice: 'nova',
        input: text,
        response_format: 'mp3', // ğŸµ MP3 í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ ë³€ê²½ (ë” ì‘ì€ íŒŒì¼ í¬ê¸°)
        speed: 1.0 // ìŒì„± ì†ë„ ì¡°ì ˆ (1.0ì´ ê¸°ë³¸)
      });

      // ğŸ”„ ì‘ë‹µì„ Bufferë¡œ ë³€í™˜í•˜ê³  ì••ì¶•
      const buffer = Buffer.from(await audioResponse.arrayBuffer());
      // const compressedBuffer = await this.compressBuffer(buffer);
      
      this.logger.debug('Text to speech conversion and compression completed');
      return buffer;
    } catch (error) {
      this.logger.error(`Error in textToSpeech: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¨ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ - DALL-E ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
  async generateImage(prompt: string): Promise<string> {
    try {
      this.logger.debug('Generating image with prompt:', prompt);
      
      const response = await this.openai.images.generate({
        model: "dall-e-3",
        prompt,
        n: 1,
        size: "1024x1024",
        quality: "standard",
        style: "natural"
      });

      const imageUrl = response.data[0].url;
      this.logger.debug('Generated image URL:', imageUrl);
      
      return imageUrl;
    } catch (error) {
      this.logger.error(`Error in generateImage: ${error.message}`, error.stack);
      throw error;
    }
  }

  /**
   * ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeImage(imageUrl: string, prompt: string): Promise<string> {
    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              { type: 'text', text: prompt },
              {
                type: 'image_url',
                image_url: { url: imageUrl }
              }
            ]
          }
        ],
        max_tokens: 500
      });

      return response.choices[0]?.message?.content || '';
    } catch (error) {
      this.logger.error(`Error analyzing image: ${error.message}`, error.stack);
      throw new Error('ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }

  /**
   * ğŸ–¼ï¸ Vision APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeImagesWithVision(
    userImageUrl: string, 
    guideImageUrl: string,
    currentStep: number,
    systemPrompt: string,
    userPrompt: string
  ): Promise<{ score: number; feedback: string }> {
    try {
      this.logger.debug('Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘');

      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: [
              { type: 'text', text: userPrompt },
              {
                type: 'image_url',
                image_url: { 
                  url: guideImageUrl,
                  detail: "high"  
                }
              },
              {
                type: 'image_url',
                image_url: { 
                  url: userImageUrl,
                  detail: "high"  
                }
              }
            ]
          }
        ],
      });

      const result = response.choices[0]?.message?.content;
      if (!result) {
        return {
          score: 0,
          feedback: 'í˜„ì¬ ê·¸ë¦¼ì„ í‰ê°€í•˜ê¸° ì–´ë ¤ìš´ ìƒí™©ì´ì—ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
        };
      }

      this.logger.debug('Raw Vision API ì‘ë‹µ:', result);
      
      // ì‘ë‹µì—ì„œ íŠ¹ì • ì—ëŸ¬ ë©”ì‹œì§€ íŒ¨í„´ í™•ì¸
      if (result.includes('ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤') || result.includes('ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')) {
        return {
          score: 0,
          feedback: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì§€ê¸ˆì€ ê·¸ë¦¼ì„ í‰ê°€í•˜ê¸° ì–´ë ¤ì›Œìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
        };
      }
      
      try {
        // ì‘ë‹µ ë¬¸ìì—´ ì •ë¦¬
        const cleanedResult = result
          .replace(/```(?:json)?\n|\n```/g, '') // ì½”ë“œ ë¸”ë¡ ì œê±°
          .replace(/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g, ''); // ê³µë°± ë¬¸ì ì œê±°
        
        this.logger.debug('ì •ë¦¬ëœ ì‘ë‹µ:', cleanedResult);
        
        const parsedResult = JSON.parse(cleanedResult);
        
        // ì‘ë‹µ í˜•ì‹ ê²€ì¦
        if (!parsedResult.score || !parsedResult.feedback) {
          return {
            score: 0,
            feedback: 'í‰ê°€ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê² ì–´ìš”?'
          };
        }

        return parsedResult;
      } catch (parseError) {
        this.logger.error('JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:', result);
        this.logger.error('íŒŒì‹± ì—ëŸ¬:', parseError);
        
        return {
          score: 0,
          feedback: 'í‰ê°€ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê² ì–´ìš”?'
        };
      }
    } catch (error) {
      this.logger.error('Vision API ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      
      return {
        score: 0,
        feedback: 'í˜„ì¬ ê·¸ë¦¼ì„ í‰ê°€í•˜ê¸° ì–´ë ¤ìš´ ìƒí™©ì´ì—ìš”. ì ì‹œ í›„ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      };
    }
  }

  
}