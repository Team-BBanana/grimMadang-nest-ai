// ğŸ¤– OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ í•„ìˆ˜ ëª¨ë“ˆ ì„í¬íŠ¸
import { Injectable, Logger } from '@nestjs/common';
import { OpenAIConfig } from '../config/openai.config';
import OpenAI from 'openai';
import { File } from '@web-std/file';
import * as zlib from 'zlib';
import { promisify } from 'util';

// gzip ì••ì¶•/í•´ì œ í•¨ìˆ˜ë¥¼ í”„ë¡œë¯¸ìŠ¤ë¡œ ë³€í™˜
const gzipAsync = promisify(zlib.gzip);
const gunzipAsync = promisify(zlib.gunzip);

// ğŸ”Œ OpenAI ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ - OpenAI APIì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬
@Injectable()
export class OpenAIService {
  // OpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•˜ëŠ” private ë³€ìˆ˜
  private readonly logger = new Logger(OpenAIService.name);
  private readonly openai: OpenAI;

  // âš¡ OpenAIConfigë¥¼ ì£¼ì…ë°›ì•„ OpenAI ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
  constructor(private readonly openaiConfig: OpenAIConfig) {
    this.openai = this.openaiConfig.getOpenAI();
  }

  // ğŸ¤ï¸ ë°ì´í„° ì••ì¶• ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  private async compressBuffer(buffer: Buffer): Promise<Buffer> {
    try {
      // GZIP ì••ì¶• ìˆ˜í–‰
      return await gzipAsync(buffer);
    } catch (error) {
      this.logger.error(`Error in compressBuffer: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¤ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Speech-to-Text)
  async speechToText(audioData: Buffer): Promise<string> {
    try {
      this.logger.debug('Converting speech to text');
      // ë°›ì€ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([audioData], 'audio.wav', { type: 'audio/wav' });
      // Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      const transcription = await this.openai.audio.transcriptions.create({
        file,
        model: 'whisper-1',
      });

      this.logger.debug('Speech to text result:', transcription.text + '\n\n');
      return transcription.text;
    } catch (error) {
      this.logger.error(`Error in speechToText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ’­ í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ - GPT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• í…ìŠ¤íŠ¸ ìƒì„±
  async generateText(prompt: string, userInput?: string): Promise<string> {
    try {
      this.logger.debug('Generating text with prompt:', prompt + '\n\n');
      // GPT-3.5-turbo ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
      const messages: { role: 'system' | 'user' | 'assistant', content: string }[] = [
        { role: 'system', content: prompt }
      ];
      
      // ì‚¬ìš©ì ì…ë ¥ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
      if (userInput) {
        messages.push({ role: 'user', content: userInput });
      }

      const completion = await this.openai.chat.completions.create({
        messages,
        model: 'gpt-4o',
      });

      const response = completion.choices[0].message.content;
      this.logger.debug('Generated text:', response + '\n\n');
      return response;
    } catch (error) {
      this.logger.error(`Error in generateText: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ” ë¶„ì„ìš© í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ (GPT-4 ëª¨ë¸ ì‚¬ìš©)
  async generateAnalysis(systemPrompt: string | OpenAI.Chat.ChatCompletionMessageParam[], userPrompt?: string): Promise<string> {
    try {
      this.logger.debug('Generating analysis with system prompt:', systemPrompt);
      this.logger.debug('User prompt for analysis:', userPrompt);

      let messages: OpenAI.Chat.ChatCompletionMessageParam[];

      if (Array.isArray(systemPrompt)) {
        messages = systemPrompt;
      } else {
        messages = [
          { role: 'user' as const, content: `${systemPrompt}\n\n${userPrompt || ''}` }
        ];
      }

      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages,
        max_completion_tokens: 500,
      });

      const response = completion.choices[0]?.message?.content || '';
      this.logger.debug('Raw AI response:', response);

      // ì‘ë‹µì—ì„œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
      const cleanedResponse = response.replace(/```(?:json)?\n|\n```/g, '').trim();
      this.logger.debug('Cleaned response:', cleanedResponse);

      return cleanedResponse;
    } catch (error) {
      this.logger.error('Error generating analysis:', error);
      throw error;
    }
  }

  // ğŸ”Š í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Text-to-Speech)
  async textToSpeech(text: string): Promise<Buffer> { // ë°˜í™˜ íƒ€ì…ì„ Bufferë¡œ ë³€ê²½
    try {
      this.logger.debug('Converting text to speech:', text);
      // TTS-1 ëª¨ë¸ê³¼ Nova ìŒì„±ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ MP3 í˜•ì‹ ìŒì„±ìœ¼ë¡œ ë³€í™˜
      const audioResponse = await this.openai.audio.speech.create({
        model: 'tts-1',
        voice: 'nova',
        input: text,
        response_format: 'mp3', // ğŸµ MP3 í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ ë³€ê²½ (ë” ì‘ì€ íŒŒì¼ í¬ê¸°)
        speed: 1.0 // ìŒì„± ì†ë„ ì¡°ì ˆ (1.0ì´ ê¸°ë³¸)
      });

      // ğŸ”„ ì‘ë‹µì„ Bufferë¡œ ë³€í™˜í•˜ê³  ì••ì¶•
      const buffer = Buffer.from(await audioResponse.arrayBuffer());
      // const compressedBuffer = await this.compressBuffer(buffer);
      
      this.logger.debug('Text to speech conversion and compression completed');
      return buffer;
    } catch (error) {
      this.logger.error(`Error in textToSpeech: ${error.message}`, error.stack);
      throw error;
    }
  }

  // ğŸ¨ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ - DALL-E ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±
  async generateImage(prompt: string): Promise<string> {
    try {
      this.logger.debug('Generating image with prompt:', prompt);
      
      const response = await this.openai.images.generate({
        model: "dall-e-3",
        prompt,
        n: 1,
        size: "1024x1024",
        quality: "standard",
        style: "natural",
        // size: "1792x1024",
        // quality: "hd",
        // style: "vivid"
      });

      const imageUrl = response.data[0].url;
      this.logger.debug('Generated image URL:', imageUrl);
      
      return imageUrl;
    } catch (error) {
      this.logger.error(`Error in generateImage: ${error.message}`, error.stack);
      throw error;
    }
  }

  /**
   * ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeImage(imageUrl: string, prompt: string): Promise<string> {
    try {
      const response = await this.openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              { type: 'text', text: prompt },
              {
                type: 'image_url',
                image_url: { 
                  url: imageUrl,
                  detail: "high"
                }
              }
            ]
          }
        ],
        max_tokens: 500
      });

      return response.choices[0]?.message?.content || '';
    } catch (error) {
      this.logger.error(`Error analyzing image: ${error.message}`, error.stack);
      throw new Error('ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }
  }

  /**
   * ğŸ–¼ï¸ Vision APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„
   */
  async analyzeImagesWithVision(
    userImageUrl: string, 
    guideImageUrl: string,
    currentStep: number,
    systemPrompt: string,
    userPrompt: string
  ): Promise<{ score: number; feedback: string }> {
    // const MAX_RETRIES = 3;  // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    let retryCount = 0;
    let lastError = null;

    while (true) {  // ë¬´í•œ ì¬ì‹œë„ë¡œ ë³€ê²½
      retryCount++;
      this.logger.debug(`ì¬ì‹œë„ íšŸìˆ˜: ${retryCount}`);
      this.logger.debug('ìœ ì € ì´ë¯¸ì§€ ì£¼ì†Œì…ë‹ˆë‹¤!!!!!!!!!!! userImageUrl:', userImageUrl);
      this.logger.debug('ê°€ì´ë“œ ì´ë¯¸ì§€ ì£¼ì†Œì…ë‹ˆë‹¤!!!!!!!!!!! guideImageUrl:', guideImageUrl);
      this.logger.debug('í˜„ì¬ ìŠ¤í…ì…ë‹ˆë‹¤!!!!!!!!!! currentStep:', currentStep);
      try {
        // this.logger.debug(`Vision API ë¶„ì„ ì‹œë„ ${retryCount + 1}/${MAX_RETRIES}`);

        const response = await this.openai.chat.completions.create({
          model: 'gpt-4o',
          messages: [
            {
              role: 'system',
              content: systemPrompt
            },
            {
              role: 'user',
              content: [
                { type: 'text', text: userPrompt },
                {
                  type: 'image_url',
                  image_url: { 
                    url: guideImageUrl,
                    detail: "high"  
                  }
                },
                {
                  type: 'image_url',
                  image_url: { 
                    url: userImageUrl,
                    detail: "high"  
                  }
                }
              ]
            }
          ],
        });

        const result = response.choices[0]?.message?.content;
        if (!result) {
          lastError = new Error('Vision API ì‘ë‹µì´ ë¹„ì–´ìˆìŒ');
          this.logger.warn('ì‘ë‹µì´ ë¹„ì–´ìˆìŒ');
          return {
            score: 0,
            feedback: 'ê·¸ë¦¼ì´ ë„ˆë¬´ íë¦¿í•˜ê±°ë‚˜ ë¶ˆë¶„ëª…í•´ìš”. ì¢€ ë” ì„ ëª…í•˜ê³  ìì„¸í•˜ê²Œ ê·¸ë ¤ì£¼ì‹œê² ì–´ìš”?'
          };
        }

        this.logger.debug('Raw Vision API ì‘ë‹µ:', result);
        
        // ì‘ë‹µì—ì„œ íŠ¹ì • ì—ëŸ¬ ë©”ì‹œì§€ íŒ¨í„´ í™•ì¸
        if (result.includes('ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤') || result.includes('ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')) {
          lastError = new Error('Vision API ì œí•œ ì‘ë‹µ');
          this.logger.warn('API ì œí•œ ì‘ë‹µ:', result);
          return {
            score: 0,
            feedback: 'ê·¸ë¦¼ì´ ì˜ ë³´ì´ì§€ ì•Šì•„ìš”. ì¡°ê¸ˆ ë” ì§„í•˜ê²Œ ê·¸ë ¤ì£¼ì‹œë©´ ì¢‹ê² ì–´ìš”.'
          };
        }
        
        try {
          // ì‘ë‹µ ë¬¸ìì—´ ì •ë¦¬
          const cleanedResult = result
            .replace(/```(?:json)?\n|\n```/g, '') // ì½”ë“œ ë¸”ë¡ ì œê±°
            .replace(/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g, '') // ê³µë°± ë¬¸ì ì œê±°
            .replace(/[\u200B-\u200D\uFEFF]/g, ''); // ì œë¡œ í­ ê³µë°± ë¬¸ì ì œê±°
          
          this.logger.debug('ì •ë¦¬ëœ ì‘ë‹µ:', cleanedResult);
          
          const parsedResult = JSON.parse(cleanedResult);
          
          // ì‘ë‹µ í˜•ì‹ ê²€ì¦
          if (!parsedResult.score || !parsedResult.feedback) {
            lastError = new Error('í•„ìˆ˜ í•„ë“œ ëˆ„ë½');
            this.logger.warn('í•„ìˆ˜ í•„ë“œ ëˆ„ë½:', parsedResult);
            return {
              score: 0,
              feedback: 'ê·¸ë¦¼ì„ ì¢€ ë” ì •ì„±ìŠ¤ëŸ½ê²Œ ê·¸ë ¤ì£¼ì‹œë©´ ë” ì˜ í‰ê°€í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.'
            };
          }

          // ì„±ê³µì ì¸ ì‘ë‹µì„ ë°›ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
          this.logger.debug('ì„±ê³µì ì¸ ì‘ë‹µ ë°›ìŒ:', parsedResult);
          return parsedResult;

        } catch (parseError) {
          lastError = parseError;
          this.logger.warn('JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:', result);
          this.logger.warn('íŒŒì‹± ì—ëŸ¬:', parseError);
          return {
            score: 0,
            feedback: 'ê·¸ë¦¼ì´ ê¸°ì¤€ ì´ë¯¸ì§€ì™€ ë„ˆë¬´ ë‹¬ë¼ìš”. ê¸°ì¤€ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•´ì„œ ë‹¤ì‹œ í•œë²ˆ ê·¸ë ¤ì£¼ì‹œê² ì–´ìš”?'
          };
        }
      } catch (error) {
        lastError = error;
        this.logger.warn('API í˜¸ì¶œ ì‹¤íŒ¨:', error);
        
        // API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
        await new Promise(resolve => setTimeout(resolve, 1000));
        continue;
      }
    }
  }

  
}